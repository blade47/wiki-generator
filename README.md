# Wiki Generator

**Transform any GitHub repository into comprehensive, AI-powered documentation with semantic code search.**

Built with advanced RAG (Retrieval-Augmented Generation) pipeline, multi-agent system, and vector search for intelligent code discovery.

---

## ğŸ¯ What It Does

1. **ğŸ“– Wiki Generation** - Analyzes GitHub repos and generates feature-focused documentation
2. **ğŸ” Semantic Search** - Natural language search across all indexed codebases
3. **ğŸ¤– AI Agents** - 4 specialized agents analyze tech stack, features, and architecture
4. **ğŸ”— GitHub Integration** - Direct links to source code with line numbers

---

## âœ¨ Key Features

### **Wiki Generation**
- Fetches code from any public GitHub repository
- Analyzes tech stack and architecture patterns
- Identifies user-facing features (not technical layers)
- Generates MDX documentation with code examples
- Stores wikis in Vercel Blob for instant access

### **Semantic Code Search**
- Natural language queries ("user authentication", "database queries")
- AI-powered vector embeddings for semantic understanding
- Search across all generated wikis
- View code snippets with GitHub source links
- Fast results with Upstash Vector

### **Multi-Agent System**
1. **Recon Agent** - Identifies tech stack, languages, frameworks, and architecture
2. **Features Agent** - Detects user-facing features from codebase structure
3. **Architecture Agent** - Analyzes architectural patterns and design
4. **Docs Generator** - Creates comprehensive documentation with code citations

---

## ğŸš€ Quick Start

```bash
# 1. Clone and install
git clone <your-repo>
cd wiki-generator
npm install

# 2. Set up environment variables
cp .env.local.example .env.local
# Edit .env.local and add:
# - OPENAI_API_KEY
# - UPSTASH_VECTOR_REST_URL
# - UPSTASH_VECTOR_REST_TOKEN

# 3. Run development server
npm run dev

# 4. Visit http://localhost:3000
```

---

## ğŸ“ Project Structure

```
wiki-generator/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ generate-wiki/      # Wiki generation endpoint
â”‚   â”‚   â”œâ”€â”€ search/             # Semantic search endpoint
â”‚   â”‚   â””â”€â”€ workflow-status/    # Workflow status polling
â”‚   â”œâ”€â”€ generate/               # Wiki generation UI
â”‚   â”œâ”€â”€ search/                 # Search UI
â”‚   â”œâ”€â”€ wiki/                   # Wiki display pages
â”‚   â””â”€â”€ page.tsx                # Home page
â”‚
â”œâ”€â”€ lib/
â”‚   â”œâ”€â”€ agents/                 # AI Agent System (4 agents)
â”‚   â”‚   â”œâ”€â”€ recon/              # Tech stack analysis
â”‚   â”‚   â”œâ”€â”€ features/           # Feature detection
â”‚   â”‚   â”œâ”€â”€ architecture/       # Pattern analysis
â”‚   â”‚   â”œâ”€â”€ docs-generator/     # Documentation generation
â”‚   â”‚   â””â”€â”€ shared/             # Agent factory & utilities
â”‚   â”œâ”€â”€ rag/                    # RAG Pipeline
â”‚   â”‚   â”œâ”€â”€ chunker.ts          # Code chunking with tree-sitter
â”‚   â”‚   â”œâ”€â”€ embedder.ts         # OpenAI embeddings
â”‚   â”‚   â”œâ”€â”€ index.ts            # RAG orchestration
â”‚   â”‚   â””â”€â”€ vector-search.ts    # Vector similarity search
â”‚   â”œâ”€â”€ github/
â”‚   â”‚   â””â”€â”€ fetcher.ts          # GitHub API client
â”‚   â”œâ”€â”€ vector-storage.ts       # Upstash Vector integration
â”‚   â”œâ”€â”€ blob-storage.ts         # Vercel Blob wiki storage
â”‚   â””â”€â”€ wiki.ts                 # Wiki loading utilities
â”‚
â”œâ”€â”€ workflows/
â”‚   â””â”€â”€ wikiGeneration/         # Main workflow
â”‚       â”œâ”€â”€ index.ts            # Orchestration
â”‚       â””â”€â”€ steps/              # Individual steps
â”‚           â”œâ”€â”€ fetchRepo.ts
â”‚           â”œâ”€â”€ buildIndex.ts
â”‚           â”œâ”€â”€ saveToVector.ts
â”‚           â”œâ”€â”€ runRecon.ts
â”‚           â”œâ”€â”€ runFeatures.ts
â”‚           â”œâ”€â”€ runArchitecture.ts
â”‚           â”œâ”€â”€ generateDocs.ts
â”‚           â””â”€â”€ saveToBlob.ts
â”‚
â””â”€â”€ components/                 # UI components (shadcn/ui)
```

---

## ğŸ›  Tech Stack

### **Frontend**
- **Next.js 15** (App Router)
- **React 19**
- **TypeScript** (strict mode)
- **Tailwind CSS** + **shadcn/ui**

### **AI & Embeddings**
- **Vercel AI SDK** (generateObject)
- **OpenAI GPT-5-mini** (agents)
- **OpenAI text-embedding-3-small** (1536 dimensions)

### **Storage & Search**
- **Upstash Vector** (semantic search, ~2KB/chunk)
- **Vercel Blob** (wiki storage, MDX files)
- **Vercel Workflow** (orchestration, retries)

### **Code Analysis**
- **tree-sitter** (AST parsing for JS/TS/Python/Go/Rust)
- **Octokit** (GitHub API)

---

## âš™ï¸ Environment Variables

Create a `.env.local` file:

```env
# Required: OpenAI API
OPENAI_API_KEY=sk-...

# Required: Upstash Vector (for search)
UPSTASH_VECTOR_REST_URL=https://...
UPSTASH_VECTOR_REST_TOKEN=...

# Optional: GitHub API (higher rate limits)
GITHUB_TOKEN=ghp_...

# Auto-added by Vercel (for Blob storage)
BLOB_READ_WRITE_TOKEN=...
```

### **Setup Instructions:**

1. **OpenAI API Key**: https://platform.openai.com/api-keys
2. **Upstash Vector**:
   - Go to https://console.upstash.com/vector
   - Create new index:
     - **Model**: None (we provide embeddings)
     - **Dimensions**: 1536
     - **Metric**: COSINE
   - Copy REST URL and token

3. **GitHub Token** (optional):
   - https://github.com/settings/tokens
   - Select: `public_repo` scope

---

## ğŸ¨ How It Works

### **Wiki Generation Workflow**

```
User enters GitHub URL (e.g., "sindresorhus/is")
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Step 1: Fetch Repository                                â”‚
â”‚  â€¢ Clone file tree via GitHub API                        â”‚
â”‚  â€¢ Filter out tests, node_modules, build artifacts       â”‚
â”‚  â€¢ Fetch up to 300 source files                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Step 2: Build RAG Index                                 â”‚
â”‚  â€¢ Parse code with tree-sitter (extract functions/classes)â”‚
â”‚  â€¢ Generate embeddings (text-embedding-3-small)          â”‚
â”‚  â€¢ Create searchable code chunks                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Step 2.5: Save to Upstash Vector                        â”‚
â”‚  â€¢ Store embeddings + metadata                           â”‚
â”‚  â€¢ Enable semantic search across repos                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Step 3: Run AI Agents (Parallel)                        â”‚
â”‚  â€¢ Recon: Analyze tech stack, languages, patterns        â”‚
â”‚  â€¢ Features: Detect user-facing features                 â”‚
â”‚  â€¢ Architecture: Identify architectural patterns         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Step 4: Generate Documentation                          â”‚
â”‚  â€¢ For each feature: find relevant code chunks           â”‚
â”‚  â€¢ Docs Generator creates MDX with examples              â”‚
â”‚  â€¢ Include code citations (file:line)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Step 5: Save Wiki to Vercel Blob                        â”‚
â”‚  â€¢ Generate index.mdx (overview)                         â”‚
â”‚  â€¢ Generate feature pages (feature-name.mdx)             â”‚
â”‚  â€¢ Store as public blobs                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“
    âœ“ Wiki ready at /wiki/repo-name
    âœ“ Searchable via semantic search
```

**Duration:** 2-5 minutes for typical repo (300 files)

---

### **Semantic Search Flow**

```
User types: "user authentication"
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. Generate Query Embedding                             â”‚
â”‚  â€¢ OpenAI text-embedding-3-small                         â”‚
â”‚  â€¢ 1536-dimensional vector                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. Vector Similarity Search                             â”‚
â”‚  â€¢ Query Upstash Vector with embedding                   â”‚
â”‚  â€¢ Cosine similarity ranking                             â”‚
â”‚  â€¢ Returns top 20 matches                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. Display Results                                      â”‚
â”‚  â€¢ Code snippet (500 chars)                              â”‚
â”‚  â€¢ File path + line numbers                              â”‚
â”‚  â€¢ Similarity score (% match)                            â”‚
â”‚  â€¢ "View on GitHub" link                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Response time:** < 1 second

---

## ğŸ¯ Core Principles

1. **KISS** - Simple, direct implementations (no over-engineering)
2. **DRY** - Reuse through utilities and shared patterns
3. **Type Safety** - Strict TypeScript, no `any` types
4. **User-Focused** - Document features, not technical layers
5. **Quality** - All code passes lint + type checks

---

## ğŸ“Š Architecture Decisions

### **Why Vector Search Only?**
- âœ… Simple, fast, accurate for semantic queries
- âœ… Handles typos and synonyms ("auth" finds "authentication")
- âœ… No complex fusion algorithms needed
- âŒ Removed BM25 hybrid search (added complexity, minimal benefit)
- âŒ Removed reranking (128K context makes it unnecessary)

### **Why Disable Code Compression?**
- âœ… GPT-4o-mini has 128K context window (can handle large chunks)
- âœ… Embeddings already truncate to 10KB (compression redundant)
- âœ… Simpler pipeline, faster processing
- âŒ Compression was slow (5 chunks at a time = 65 seconds)
- âŒ Added complexity without clear benefit

### **Why Snippet-Only in Search?**
- âœ… Upstash Vector has 48KB metadata limit
- âœ… Full code (10KB+) exceeds limit
- âœ… 500-char snippets sufficient for preview
- âœ… "View on GitHub" provides full context
- ğŸ“ Future: Hybrid storage (Vector + Blob) for full code on-demand

### **Why Filter Test Files?**
- âœ… Focus on implementation code
- âœ… Faster processing (skip 30-40% of files)
- âœ… Better feature detection (tests don't represent features)
- âœ… Reduced API costs

---

## ğŸ’° Cost Analysis

### **Per Large Repository (~300 files)**
```
GitHub API:        Free (60 req/hour w/o token, 5000/hour with)
Embeddings:        300 chunks Ã— $0.00002 = $0.006
Agent calls:       ~6 calls Ã— $0.15 = $0.90
Total per wiki:    ~$0.91

Monthly costs (10 wikis/month):
OpenAI:            ~$9/month
Upstash Vector:    Free tier (up to 10K vectors)
Vercel Blob:       ~$0.15/month (1GB storage)
Total:             ~$9.15/month
```

---

## âš ï¸ Known Limitations

### **Current Constraints:**
1. **No Incremental Updates** - Must regenerate entire wiki for changes
2. **Snippet-Only Search** - 500-char limit (full code on GitHub)
3. **No Authentication** - All wikis are public
4. **No Rate Limiting** - Can be abused
5. **No Caching** - Same repo re-analyzed costs same amount
6. **Single Model** - No fallback if OpenAI is down

### **Future Improvements**:
- [ ] Incremental updates with Merkle trees (90% cost reduction)
- [ ] Full code storage (Blob + Vector hybrid)
- [ ] Authentication & user workspaces
- [ ] Caching layer (Redis) for embeddings and agents
- [ ] Model fallbacks (Anthropic, Gemini)
- [ ] Private repo support (user GitHub tokens)
- [ ] Improve docs quality 
  - we slice chunks (which is a shortcut). In production app we should find a way to scan complete files. 
  - tried to scan ALL the chunks using parallel agents, but reconstruction and deduplication created akward results.
  - need more time to explore other solutions.

---

## ğŸ§ª Development

### **Commands**
```bash
# Development
npm run dev              # Start dev server (http://localhost:3000)
npm run build            # Production build
npm run start            # Start production server

# Quality checks (must pass before commit)
npm run lint             # ESLint (0 errors allowed)
npx tsc --noEmit        # TypeScript checking

# Testing
npm run test:rag         # Test RAG pipeline
npm run test:github      # Test GitHub fetcher
npm run test:docs        # Test docs generation
```

### **Code Quality Standards**
- âœ… All code passes ESLint (0 errors, 0 warnings)
- âœ… All code passes TypeScript type checking
- âœ… No `any` types (use `unknown` or specific types)
- âœ… Proper error handling with try/catch
- âœ… Clear, concise comments

### **Agent Development Pattern**

Each agent follows strict 4-file structure:

```
lib/agents/[agent-name]/
â”œâ”€â”€ schema.ts      # Zod validation schema
â”œâ”€â”€ types.ts       # Input/Output TypeScript types
â”œâ”€â”€ prompt.ts      # System + User message builders
â””â”€â”€ index.ts       # Agent definition with defineAgent()
```

Example:
```typescript
// schema.ts
export const myAgentSchema = z.object({
  result: z.string(),
  confidence: z.number(),
});

// types.ts
export type MyAgentOutput = z.infer<typeof myAgentSchema>;
export interface MyAgentInput { context: RepoContext; }

// prompt.ts
export const SYSTEM_MESSAGE = `You are an expert...`;
export function buildUserMessage(input: MyAgentInput): string { ... }

// index.ts
export const myAgent = defineAgent({
  name: 'my-agent',
  schema: myAgentSchema,
  systemMessage: SYSTEM_MESSAGE,
  buildUserMessage,
});
```

---

## ğŸš¢ Deployment

### **Vercel (Recommended)**
```bash
# Install Vercel CLI
npm i -g vercel

# Deploy
vercel

# Set environment variables in dashboard:
# - OPENAI_API_KEY
# - UPSTASH_VECTOR_REST_URL
# - UPSTASH_VECTOR_REST_TOKEN
# - GITHUB_TOKEN (optional)
```

### **Other Platforms**
Requires:
- Node.js 20+
- Support for Vercel Workflow (or alternative orchestration)
- Environment variables configured

---

## ğŸ“ License

MIT

---

**Built with â¤ï¸ using AI-powered development**
