# Wiki Generator

**Transform any GitHub repository into comprehensive, AI-powered documentation with semantic code search.**

Built with advanced RAG (Retrieval-Augmented Generation) pipeline, **knowledge graph for code relationships**, multi-agent system, and vector search for intelligent code discovery.

---

## ğŸ¯ What It Does

1. **ğŸ“– Wiki Generation** - Analyzes GitHub repos and generates feature-focused documentation
2. **ğŸ§  Knowledge Graph** - Discovers complete features by following function calls
3. **ğŸ” Semantic Search** - Natural language search across all indexed codebases
4. **ğŸ¤– AI Agents** - 4 specialized agents analyze tech stack, features, and architecture
5. **ğŸ”— GitHub Integration** - Direct links to source code with line numbers

---

## âœ¨ Key Features

### **Wiki Generation**
- Fetches code from any public GitHub repository
- Builds knowledge graph from function calls (discovers code relationships)
- Analyzes tech stack and architecture patterns
- Identifies user-facing features with complete code flows
- Generates MDX documentation with code examples
- Stores wikis in Vercel Blob for instant access

### **Semantic Code Search**
- Natural language queries ("user authentication", "database queries")
- AI-powered vector embeddings for semantic understanding
- Search across all generated wikis
- View code snippets with GitHub source links
- Fast results with Upstash Vector

### **Multi-Agent System**
1. **Recon Agent** - Identifies tech stack, languages, frameworks, and architecture
2. **Features Agent** - Detects user-facing features using knowledge graph (follows function calls to discover complete features)
3. **Architecture Agent** - Analyzes architectural patterns and design
4. **Docs Generator** - Creates comprehensive documentation with code citations

### **Knowledge Graph**
- Extracts function calls from code using AST parsing (all languages supported)
- Builds graph: `function A` â†’ calls â†’ `function B` â†’ calls â†’ `function C`
- Discovers complete features by finding entry points and traversing the graph
- Example: `login()` â†’ discovers `validateInput()`, `findUser()`, `generateToken()` (complete auth flow)

---

## ğŸš€ Quick Start

```bash
# 1. Clone and install
git clone <your-repo>
cd wiki-generator
npm install

# 2. Set up environment variables
cp .env.local.example .env.local
# Edit .env.local and add:
# - OPENAI_API_KEY
# - UPSTASH_VECTOR_REST_URL
# - UPSTASH_VECTOR_REST_TOKEN

# 3. Run development server
npm run dev

# 4. Visit http://localhost:3000
```

---

## ğŸ“ Project Structure

```
wiki-generator/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ generate-wiki/      # Wiki generation endpoint
â”‚   â”‚   â”œâ”€â”€ search/             # Semantic search endpoint
â”‚   â”‚   â””â”€â”€ workflow-status/    # Workflow status polling
â”‚   â”œâ”€â”€ generate/               # Wiki generation UI
â”‚   â”œâ”€â”€ search/                 # Search UI
â”‚   â”œâ”€â”€ wiki/                   # Wiki display pages
â”‚   â””â”€â”€ page.tsx                # Home page
â”‚
â”œâ”€â”€ lib/
â”‚   â”œâ”€â”€ agents/                 # AI Agent System (4 agents)
â”‚   â”‚   â”œâ”€â”€ recon/              # Tech stack analysis
â”‚   â”‚   â”œâ”€â”€ features/           # Feature detection
â”‚   â”‚   â”œâ”€â”€ architecture/       # Pattern analysis
â”‚   â”‚   â”œâ”€â”€ docs-generator/     # Documentation generation
â”‚   â”‚   â””â”€â”€ shared/             # Agent factory & utilities
â”‚   â”œâ”€â”€ rag/                    # RAG Pipeline
â”‚   â”‚   â”œâ”€â”€ chunker.ts          # Code chunking with tree-sitter
â”‚   â”‚   â”œâ”€â”€ embedder.ts         # OpenAI embeddings
â”‚   â”‚   â”œâ”€â”€ index.ts            # RAG orchestration
â”‚   â”‚   â””â”€â”€ vector-search.ts    # Vector similarity search
â”‚   â”œâ”€â”€ github/
â”‚   â”‚   â””â”€â”€ fetcher.ts          # GitHub API client
â”‚   â”œâ”€â”€ vector-storage.ts       # Upstash Vector integration
â”‚   â”œâ”€â”€ blob-storage.ts         # Vercel Blob wiki storage
â”‚   â””â”€â”€ wiki.ts                 # Wiki loading utilities
â”‚
â”œâ”€â”€ workflows/
â”‚   â””â”€â”€ wikiGeneration/         # Main workflow
â”‚       â”œâ”€â”€ index.ts            # Orchestration (parallel execution)
â”‚       â””â”€â”€ steps/              # Individual steps
â”‚           â”œâ”€â”€ fetchRepo.ts
â”‚           â”œâ”€â”€ buildIndex.ts   # Includes vector storage
â”‚           â”œâ”€â”€ runRecon.ts
â”‚           â”œâ”€â”€ runFeatures.ts
â”‚           â”œâ”€â”€ runArchitecture.ts
â”‚           â”œâ”€â”€ generateDocs.ts
â”‚           â””â”€â”€ saveToBlob.ts
â”‚
â””â”€â”€ components/                 # UI components (shadcn/ui)
```

---

## ğŸ›  Tech Stack

### **Frontend**
- **Next.js 15** (App Router)
- **React 19**
- **TypeScript** (strict mode)
- **Tailwind CSS** + **shadcn/ui**

### **AI & Embeddings**
- **Vercel AI SDK** (generateObject)
- **OpenAI GPT-5-mini** (agents)
- **OpenAI text-embedding-3-small** (1536 dimensions)

### **Storage & Search**
- **Upstash Vector** (semantic search, ~2KB/chunk)
- **Vercel Blob** (wiki storage, MDX files)
- **Vercel Workflow** (orchestration, retries)

### **Code Analysis**
- **tree-sitter** (AST parsing for JS/TS/Python/Go/Rust)
- **Knowledge Graph** (in-memory graph for code relationships)
- **Octokit** (GitHub API)

---

## âš™ï¸ Environment Variables

Create a `.env.local` file:

```env
# Required: OpenAI API
OPENAI_API_KEY=sk-...

# Required: Upstash Vector (for search)
UPSTASH_VECTOR_REST_URL=https://...
UPSTASH_VECTOR_REST_TOKEN=...

# Optional: GitHub API (higher rate limits)
GITHUB_TOKEN=ghp_...

# Auto-added by Vercel (for Blob storage)
BLOB_READ_WRITE_TOKEN=...
```

### **Setup Instructions:**

1. **OpenAI API Key**: https://platform.openai.com/api-keys
2. **Upstash Vector**:
   - Go to https://console.upstash.com/vector
   - Create new index:
     - **Model**: None (we provide embeddings)
     - **Dimensions**: 1536
     - **Metric**: COSINE
   - Copy REST URL and token

3. **GitHub Token** (optional):
   - https://github.com/settings/tokens
   - Select: `public_repo` scope

---

## ğŸ¨ How It Works

### **Wiki Generation Workflow**

```
User enters GitHub URL (e.g., "sindresorhus/is")
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Step 1: Fetch Repository                                â”‚
â”‚  â€¢ Clone file tree via GitHub API                        â”‚
â”‚  â€¢ Filter out tests, node_modules, build artifacts       â”‚
â”‚  â€¢ Fetch up to 300 source files                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Step 2a: Build RAG Index â”‚ Step 2b: Run Recon Agent   â”‚
â”‚  (PARALLEL)                â”‚ (PARALLEL)                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â€¢ Parse top 150 chunks    â”‚ â€¢ Analyze README            â”‚
â”‚  â€¢ Generate embeddings     â”‚ â€¢ Detect tech stack         â”‚
â”‚  â€¢ Truncate code to 3KB    â”‚ â€¢ Identify patterns         â”‚
â”‚  â€¢ Save to Upstash Vector  â”‚ â€¢ Map directory structure   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Step 3a: Features Agent   â”‚ Step 3b: Architecture Agentâ”‚
â”‚  (PARALLEL)                â”‚ (PARALLEL)                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â€¢ Top 50 chunks (3KB max) â”‚ â€¢ Top 30 chunks (3KB max)   â”‚
â”‚  â€¢ Detect user features    â”‚ â€¢ Identify patterns         â”‚
â”‚  â€¢ Rate importance (1-10)  â”‚ â€¢ Explain data flow         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Step 4: Generate Documentation (Important Features)    â”‚
â”‚  â€¢ Filter features: importance >= 4 only (focus quality)â”‚
â”‚  â€¢ For each feature: find relevant code chunks          â”‚
â”‚  â€¢ Docs Generator creates MDX with examples (3K tokens) â”‚
â”‚  â€¢ Include code citations (file:line)                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Step 5: Save Wiki to Vercel Blob                        â”‚
â”‚  â€¢ Generate index.mdx (overview)                         â”‚
â”‚  â€¢ Generate feature pages (feature-name.mdx)             â”‚
â”‚  â€¢ Store as public blobs                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“
    âœ“ Wiki ready at /wiki/repo-name
    âœ“ Searchable via semantic search
```

**Duration:** ~1.5-2 minutes for typical repo (300 files)

### **Performance Optimizations**
1. **Parallel Execution**: Recon + Index building run concurrently (saves 9s)
2. **Limited Embeddings**: Only top 150 chunks embedded (70% faster, 70% cheaper)
3. **Chunk Truncation**: 3KB max per chunk for agents (prevents context overflow)
4. **Parallel Agents**: Features + Architecture run concurrently (saves 30s)
5. **Feature Filtering**: Only document important features (importance â‰¥ 4)
6. **Increased Parallelism**:
   - GitHub fetching: 50 files/batch (was 20)
   - Embeddings: 10 concurrent batches (was 3)

---

### **Semantic Search Flow**

```
User types: "user authentication"
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. Generate Query Embedding                             â”‚
â”‚  â€¢ OpenAI text-embedding-3-small                         â”‚
â”‚  â€¢ 1536-dimensional vector                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. Vector Similarity Search                             â”‚
â”‚  â€¢ Query Upstash Vector with embedding                   â”‚
â”‚  â€¢ Cosine similarity ranking                             â”‚
â”‚  â€¢ Returns top 20 matches                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. Display Results                                      â”‚
â”‚  â€¢ Code snippet (500 chars)                              â”‚
â”‚  â€¢ File path + line numbers                              â”‚
â”‚  â€¢ Similarity score (% match)                            â”‚
â”‚  â€¢ "View on GitHub" link                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Response time:** < 1 second

---

## ğŸ¯ Core Principles

1. **KISS** - Simple, direct implementations (no over-engineering)
2. **DRY** - Reuse through utilities and shared patterns
3. **Type Safety** - Strict TypeScript, no `any` types
4. **User-Focused** - Document features, not technical layers
5. **Quality** - All code passes lint + type checks

---

## ğŸ“Š Architecture Decisions

### **Why Vector Search Only?**
- âœ… Simple, fast, accurate for semantic queries
- âœ… Handles typos and synonyms ("auth" finds "authentication")
- âœ… No complex fusion algorithms needed
- âŒ Removed BM25 hybrid search (added complexity, minimal benefit)
- âŒ Removed reranking (128K context makes it unnecessary)

### **Why Truncate Instead of Compress?**
- âœ… **Speed**: Instant vs 60s for AI compression (100x faster)
- âœ… **Coverage**: 50 chunks Ã— 3KB = 150KB (vs 20 chunks Ã— 2KB = 40KB compressed)
- âœ… **Quality**: First 3KB captures function signatures, logic, JSDoc
- âœ… **Cost**: Free vs API calls for each chunk
- âŒ Compression was too slow (code-summarizer agent took 60s for 20 chunks)
- âŒ Agents need breadth (many examples) > depth (complete implementations)
- ğŸ“ Trade-off: Agents see truncated code, but full code still in Vector for search

### **Why Snippet-Only in Search?**
- âœ… Upstash Vector has 48KB metadata limit
- âœ… Full code (10KB+) exceeds limit
- âœ… 500-char snippets sufficient for preview
- âœ… "View on GitHub" provides full context
- ğŸ“ Future: Hybrid storage (Vector + Blob) for full code on-demand

### **Why Filter Test Files?**
- âœ… Focus on implementation code
- âœ… Faster processing (skip 30-40% of files)
- âœ… Better feature detection (tests don't represent features)
- âœ… Reduced API costs

---

## ğŸ’° Cost Analysis

### **Per Large Repository (~300 files)**
```
GitHub API:        Free (60 req/hour w/o token, 5000/hour with)
Embeddings:        150 chunks Ã— $0.00002 = $0.003 (70% reduction!)
Agent calls:       ~6 calls Ã— $0.15 = $0.90
Total per wiki:    ~$0.90

Monthly costs (10 wikis/month):
OpenAI:            ~$9/month
Upstash Vector:    Free tier (up to 10K vectors)
Vercel Blob:       ~$0.15/month (1GB storage)
Total:             ~$9.15/month

Performance: 3.5 min â†’ 1.5 min (57% faster)
```

---

## âš ï¸ Known Limitations

### **Current Constraints:**
1. **No Incremental Updates** - Must regenerate entire wiki for changes
2. **Snippet-Only Search** - 500-char limit (full code on GitHub)
3. **Truncated Code for Agents** - Chunks limited to 3KB to fit context windows
   - Trade-off: Speed & reliability > complete code visibility
   - First 3KB captures signatures, logic, JSDoc (usually sufficient)
4. **Important Features Only** - Only generates docs for importance â‰¥ 4
   - Trade-off: Quality & speed > comprehensive coverage
5. **No Authentication** - All wikis are public
6. **No Rate Limiting** - Can be abused
7. **No Caching** - Same repo re-analyzed costs same amount
8. **Single Model** - No fallback if OpenAI is down

### **Future Improvements**:
- [ ] Incremental updates with Merkle trees (90% cost reduction)
- [ ] Full code storage (Blob + Vector hybrid)
- [ ] Authentication & user workspaces
- [ ] Caching layer (Redis) for embeddings and agents
- [ ] Model fallbacks (Anthropic, Gemini)
- [ ] Private repo support (user GitHub tokens)
- [ ] Smart code completion for truncated chunks
  - Current: Hard truncate at 3KB (fast, predictable)
  - Future: Intelligent truncation at semantic boundaries (end of function/class)
  - Or: Dynamic chunk sizing based on available context budget

---

## ğŸ§ª Development

### **Commands**
```bash
# Development
npm run dev              # Start dev server (http://localhost:3000)
npm run build            # Production build
npm run start            # Start production server

# Quality checks (must pass before commit)
npm run lint             # ESLint (0 errors allowed)
npx tsc --noEmit        # TypeScript checking

# Testing
npm run test:rag         # Test RAG pipeline
npm run test:github      # Test GitHub fetcher
npm run test:docs        # Test docs generation
```

### **Code Quality Standards**
- âœ… All code passes ESLint (0 errors, 0 warnings)
- âœ… All code passes TypeScript type checking
- âœ… No `any` types (use `unknown` or specific types)
- âœ… Proper error handling with try/catch
- âœ… Clear, concise comments

### **Agent Development Pattern**

Each agent follows strict 4-file structure:

```
lib/agents/[agent-name]/
â”œâ”€â”€ schema.ts      # Zod validation schema
â”œâ”€â”€ types.ts       # Input/Output TypeScript types
â”œâ”€â”€ prompt.ts      # System + User message builders
â””â”€â”€ index.ts       # Agent definition with defineAgent()
```

Example:
```typescript
// schema.ts
export const myAgentSchema = z.object({
  result: z.string(),
  confidence: z.number(),
});

// types.ts
export type MyAgentOutput = z.infer<typeof myAgentSchema>;
export interface MyAgentInput { context: RepoContext; }

// prompt.ts
export const SYSTEM_MESSAGE = `You are an expert...`;
export function buildUserMessage(input: MyAgentInput): string { ... }

// index.ts
export const myAgent = defineAgent({
  name: 'my-agent',
  schema: myAgentSchema,
  systemMessage: SYSTEM_MESSAGE,
  buildUserMessage,
});
```

---

## ğŸš¢ Deployment

### **Vercel (Recommended)**
```bash
# Install Vercel CLI
npm i -g vercel

# Deploy
vercel

# Set environment variables in dashboard:
# - OPENAI_API_KEY
# - UPSTASH_VECTOR_REST_URL
# - UPSTASH_VECTOR_REST_TOKEN
# - GITHUB_TOKEN (optional)
```

### **Other Platforms**
Requires:
- Node.js 20+
- Support for Vercel Workflow (or alternative orchestration)
- Environment variables configured

---

## ğŸ“ License

MIT

---

**Built with â¤ï¸ using AI-powered development**
